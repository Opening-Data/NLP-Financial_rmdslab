{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0d591f-edf1-49df-8368-8e983d6ffb20",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting Insights from Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ab047-9622-4ae2-baf1-e4e38716f1b4",
   "metadata": {},
   "source": [
    "### Use NLP to extract context from Financial news headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd029ba1-54d2-4f99-9162-da03dcc7f7fc",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8455e13-7caa-4e48-b0ce-ecf150e94b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Libraries for Text Pre-processing\n",
    "import re, string\n",
    "string.punctuation\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "#Libraries for Model Building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# Libraries for Bag of Words Model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Libraries for Word Embedding\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3035fda4-0d67-46d0-9091-054a1fc60e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856ec34-5913-41e4-bc30-1fd94b400e28",
   "metadata": {},
   "source": [
    "### 2. Load & Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7bb769c-8866-4d5a-959b-268e90016751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9994 entries, 0 to 9993\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   date     9993 non-null   object\n",
      " 1   group    9861 non-null   object\n",
      " 2   Class    9994 non-null   object\n",
      " 3   ClassID  9994 non-null   int64 \n",
      " 4   title    9886 non-null   object\n",
      " 5   URL      9886 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 468.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>group</th>\n",
       "      <th>Class</th>\n",
       "      <th>ClassID</th>\n",
       "      <th>title</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>October 19 2021</td>\n",
       "      <td>Bank of England</td>\n",
       "      <td>Finance</td>\n",
       "      <td>1</td>\n",
       "      <td>Traders fear policymakers will move too aggres...</td>\n",
       "      <td>https://www.ft.com/content/45febe54-ca7a-40ff-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>October 18 2021</td>\n",
       "      <td>The Road to Recovery</td>\n",
       "      <td>Finance</td>\n",
       "      <td>1</td>\n",
       "      <td>Hopes damped over extra gas from Russia; Europ...</td>\n",
       "      <td>https://www.ft.com/content/0ba98a96-a4fc-4f35-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>October 18 2021</td>\n",
       "      <td>Sheikh Hasina</td>\n",
       "      <td>Finance</td>\n",
       "      <td>1</td>\n",
       "      <td>My country is investing for a zero-carbon futu...</td>\n",
       "      <td>https://www.ft.com/content/67b17114-5503-4db6-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>October 18 2021</td>\n",
       "      <td>UK inflation</td>\n",
       "      <td>Finance</td>\n",
       "      <td>1</td>\n",
       "      <td>Damn, or be damned.</td>\n",
       "      <td>https://www.ft.com/content/5a94cb7b-f918-40ee-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October 18 2021</td>\n",
       "      <td>Gideon Rachman</td>\n",
       "      <td>Finance</td>\n",
       "      <td>1</td>\n",
       "      <td>The US president’s domestic problems are hobbl...</td>\n",
       "      <td>https://www.ft.com/content/76ad8f97-3927-4a55-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                 group    Class  ClassID  \\\n",
       "0  October 19 2021       Bank of England  Finance        1   \n",
       "1  October 18 2021  The Road to Recovery  Finance        1   \n",
       "2  October 18 2021         Sheikh Hasina  Finance        1   \n",
       "3  October 18 2021          UK inflation  Finance        1   \n",
       "4  October 18 2021        Gideon Rachman  Finance        1   \n",
       "\n",
       "                                               title  \\\n",
       "0  Traders fear policymakers will move too aggres...   \n",
       "1  Hopes damped over extra gas from Russia; Europ...   \n",
       "2  My country is investing for a zero-carbon futu...   \n",
       "3                                Damn, or be damned.   \n",
       "4  The US president’s domestic problems are hobbl...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.ft.com/content/45febe54-ca7a-40ff-...  \n",
       "1  https://www.ft.com/content/0ba98a96-a4fc-4f35-...  \n",
       "2  https://www.ft.com/content/67b17114-5503-4db6-...  \n",
       "3  https://www.ft.com/content/5a94cb7b-f918-40ee-...  \n",
       "4  https://www.ft.com/content/76ad8f97-3927-4a55-...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('World_Economy.csv',parse_dates=True)\n",
    "\n",
    "data.info()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8912971-8a5e-48ad-9c7b-65e7df21c95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9994, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11aa3dc1-8a1e-4e44-80c3-e68219f6a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define test & train sets\n",
    "df_train= pd.read_csv('train_data.csv')\n",
    "df_test=pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acdfa996-710e-4274-9577-35f0adec5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to lowercase, strip and remove punctuations\n",
    "df_train.title=df_train.title.astype(str)\n",
    "df_test.title=df_test.title.astype(str)\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()  \n",
    "    text=re.compile('<.*?>').sub('', text) \n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  \n",
    "    text = re.sub('\\s+', ' ', text)  \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) \n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e9f6520-6a7b-4575-b451-77fa81eb38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15497a07-a8fd-41f2-823d-f82799fa1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    " \n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b166859-98d1-47d9-8b3a-a478177e1a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>group</th>\n",
       "      <th>Class</th>\n",
       "      <th>ClassID</th>\n",
       "      <th>title</th>\n",
       "      <th>URL</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>October 14 2021</td>\n",
       "      <td>Ngozi Okonjo-Iweala</td>\n",
       "      <td>Finance</td>\n",
       "      <td>1</td>\n",
       "      <td>A common approach to the cost of polluting is ...</td>\n",
       "      <td>https://www.ft.com/content/b0bcc93c-c6d6-475e-...</td>\n",
       "      <td>common approach cost pollute fair straightforw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>October 14 2021</td>\n",
       "      <td>Martin Sandbu</td>\n",
       "      <td>Finance</td>\n",
       "      <td>1</td>\n",
       "      <td>IEA report shows current pledges fall short — ...</td>\n",
       "      <td>https://www.ft.com/content/9918f2da-131f-4f2a-...</td>\n",
       "      <td>iea report show current pledge fall short poin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>October 14 2021</td>\n",
       "      <td>Turkish economy</td>\n",
       "      <td>Fintech</td>\n",
       "      <td>0</td>\n",
       "      <td>President removes two deputy governors in new ...</td>\n",
       "      <td>https://www.ft.com/content/88cbe503-e5a0-40d4-...</td>\n",
       "      <td>president remove two deputy governor new round...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>October 14 2021</td>\n",
       "      <td>Chinese economy</td>\n",
       "      <td>Fintech</td>\n",
       "      <td>0</td>\n",
       "      <td>Producer price index climbs 10.7% cent in Sept...</td>\n",
       "      <td>https://www.ft.com/content/75871eb7-360e-40b5-...</td>\n",
       "      <td>producer price index climb cent september year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October 14 2021</td>\n",
       "      <td>FT Magazine</td>\n",
       "      <td>Fintech</td>\n",
       "      <td>0</td>\n",
       "      <td>The country’s supply issues have been exacerba...</td>\n",
       "      <td>https://www.ft.com/content/ff650169-34bc-4ac9-...</td>\n",
       "      <td>countrys supply issue exacerbate brexit thats ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                group    Class  ClassID  \\\n",
       "0  October 14 2021  Ngozi Okonjo-Iweala  Finance        1   \n",
       "1  October 14 2021        Martin Sandbu  Finance        1   \n",
       "2  October 14 2021      Turkish economy  Fintech        0   \n",
       "3  October 14 2021      Chinese economy  Fintech        0   \n",
       "4  October 14 2021          FT Magazine  Fintech        0   \n",
       "\n",
       "                                               title  \\\n",
       "0  A common approach to the cost of polluting is ...   \n",
       "1  IEA report shows current pledges fall short — ...   \n",
       "2  President removes two deputy governors in new ...   \n",
       "3  Producer price index climbs 10.7% cent in Sept...   \n",
       "4  The country’s supply issues have been exacerba...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.ft.com/content/b0bcc93c-c6d6-475e-...   \n",
       "1  https://www.ft.com/content/9918f2da-131f-4f2a-...   \n",
       "2  https://www.ft.com/content/88cbe503-e5a0-40d4-...   \n",
       "3  https://www.ft.com/content/75871eb7-360e-40b5-...   \n",
       "4  https://www.ft.com/content/ff650169-34bc-4ac9-...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  common approach cost pollute fair straightforw...  \n",
       "1  iea report show current pledge fall short poin...  \n",
       "2  president remove two deputy governor new round...  \n",
       "3  producer price index climb cent september year...  \n",
       "4  countrys supply issue exacerbate brexit thats ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))\n",
    "df_train['clean_text'] = df_train['title'].apply(lambda x: finalpreprocess(x))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f5a4a-3aca-4c40-96d1-7a5f9af56979",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f96cf42-d4a3-43e5-a011-b6fc3b878f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[\"clean_text\"],df_train[\"ClassID\"],test_size=0.2,shuffle=True)\n",
    "#Word2Vec\n",
    "# Word2Vec runs on tokenized sentences\n",
    "X_train_tok= [nltk.word_tokenize(i) for i in X_train]  \n",
    "X_test_tok= [nltk.word_tokenize(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def99316-2198-4fc7-88dc-7cb7c30a0ec2",
   "metadata": {},
   "source": [
    "### using Bag-of-Words (with Tf-Idf ) and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef010d-04bb-4af2-83c4-f47f9f6d8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(next(iter(word2vec.values())))\n",
    "def fit(self, X, y):\n",
    "        return self\n",
    "def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "model = Word2Vec(df['clean_text_tok'],min_count=1) \n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0)) \n",
    "df['clean_text_tok']=[nltk.word_tokenize(i) for i in df['clean_text']]\n",
    "modelw = MeanEmbeddingVectorizer(w2v)\n",
    "# converting text to numerical data using Word2Vec\n",
    "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
    "X_val_vectors_w2v = modelw.transform(X_test_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025d4af-b37e-4438-a07d-92f899ab285c",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff71419-93d6-40de-ac34-c67a72f11832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression(tf-idf)\n",
    "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = lr_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1c074-69ba-4e8f-b1c5-71118a24fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Logistic Regression (W2v)\n",
    "lr_w2v=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
    "lr_w2v.fit(X_train_vectors_w2v, y_train)  #model\n",
    "#Predict y value for test dataset\n",
    "y_predict = lr_w2v.predict(X_test_vectors_w2v)\n",
    "y_prob = lr_w2v.predict_proba(X_test_vectors_w2v)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b015a38c-3258-43e4-a038-d3ff38734a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1176\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           1.00      1177\n",
      "   macro avg       0.50      0.50      0.50      1177\n",
      "weighted avg       1.00      1.00      1.00      1177\n",
      "\n",
      "Confusion Matrix: [[1176    0]\n",
      " [   1    0]]\n",
      "AUC: 0.9481292517006802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z0047e4y\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\z0047e4y\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\z0047e4y\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#FITTING THE CLASSIFICATION MODEL using Naive Bayes(tf-idf)\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_vectors_tfidf, y_train)  \n",
    "#Predict y value for test dataset\n",
    "y_predict = nb_tfidf.predict(X_test_vectors_tfidf)\n",
    "y_prob = nb_tfidf.predict_proba(X_test_vectors_tfidf)[:,1]\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))\n",
    " \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b8803-fd09-484e-9853-f0f3d54f2875",
   "metadata": {},
   "source": [
    "## Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "466cefcc-0bff-40fc-8b22-bc1867387296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  target\n",
      "0  move save taxpayer billion pound year hit pens...       0\n",
      "1  kremlin critic say sue sanction breach credit ...       0\n",
      "2  beggar thy neighbour battle business benefit p...       0\n",
      "3  eu ombudsman say decision expose weakness comm...       0\n",
      "4  uk bank warn vulnerability economic effect mul...       0\n"
     ]
    }
   ],
   "source": [
    "#Pre-processing the new dataset\n",
    "df_test['clean_text'] = df_test['title'].apply(lambda x: finalpreprocess(x)) #preprocess the data\n",
    "X_test=df_test['clean_text'] \n",
    "#converting words to numerical data using tf-idf\n",
    "X_vector=tfidf_vectorizer.transform(X_test)\n",
    "#use the best model to predict 'target' value for the new dataset \n",
    "y_predict = lr_tfidf.predict(X_vector)      \n",
    "y_prob = lr_tfidf.predict_proba(X_vector)[:,1]\n",
    "df_test['predict_prob']= y_prob\n",
    "df_test['target']= y_predict\n",
    "final=df_test[['clean_text','target']].reset_index(drop=True)\n",
    "print(final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8f2d6-1b4d-48aa-8d91-7b4603acc951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
